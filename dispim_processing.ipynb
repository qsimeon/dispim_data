{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Double-diSPIM Processing Pipeline\n",
        "\n",
        "This notebook implements the complete processing pipeline to transform raw double-diSPIM data into a single, isotropic, high-resolution 3D volume.\n",
        "\n",
        "## Pipeline Overview\n",
        "\n",
        "1. **Deskewing**: Remove 45° shear from light sheet imaging\n",
        "2. **Intra-Arm Alignment**: Align cameras within each arm (Alpha: A↔B, Beta: C↔D)\n",
        "3. **Rough Inter-Arm Alignment**: Transform Beta arm to match Alpha coordinate system\n",
        "4. **Fine Registration**: Precise alignment of Beta to Alpha using overlapping regions\n",
        "5. **Fusion**: Combine all 4 registered volumes into single isotropic volume\n",
        "\n",
        "## System Geometry\n",
        "\n",
        "- **Alpha Arm (Top)**: Views from above, imaging XZ plane\n",
        "- **Beta Arm (Bottom)**: Views from below, rotated 90° around Z-axis, imaging YZ plane\n",
        "- Each arm has 2 cameras that need spatial alignment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import data loading functions\n",
        "from utils import (\n",
        "    parse_metadata,\n",
        "    load_ome_tiff,\n",
        "    discover_acquisitions,\n",
        "    extract_spatial_info,\n",
        "    scale_image_for_display,\n",
        "    create_camera_overlay\n",
        ")\n",
        "\n",
        "# Import processing functions\n",
        "from processing import (\n",
        "    deskew_stack,\n",
        "    calculate_deskew_matrix,\n",
        "    rough_align_beta_to_alpha,\n",
        "    flip_z_axis,\n",
        "    rotate_xy_90deg,\n",
        "    align_cameras_within_arm,\n",
        "    register_arms,\n",
        "    apply_transform,\n",
        "    fuse_volumes,\n",
        "    compute_mip,\n",
        "    compute_mip_xyz\n",
        ")\n",
        "\n",
        "# Set up matplotlib\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (15, 8)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Load Data and Define Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Discover acquisitions\n",
        "acquisitions = discover_acquisitions('./datasets')\n",
        "print(f\"Found {len(acquisitions)} acquisition pairs\")\n",
        "\n",
        "# Select acquisition to process\n",
        "ACQUISITION_INDEX = 0\n",
        "\n",
        "if len(acquisitions) > ACQUISITION_INDEX:\n",
        "    selected_acq = acquisitions[ACQUISITION_INDEX]\n",
        "    print(f\"\\nSelected: {selected_acq['condition']}/{selected_acq['run']}\")\n",
        "else:\n",
        "    print(f\"Error: Acquisition index {ACQUISITION_INDEX} not available\")\n",
        "    selected_acq = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load metadata\n",
        "if selected_acq:\n",
        "    alpha_meta = parse_metadata(selected_acq['alpha_metadata'])\n",
        "    beta_meta = parse_metadata(selected_acq['beta_metadata'])\n",
        "    \n",
        "    # Extract key parameters for processing\n",
        "    pixel_size_um = extract_spatial_info(alpha_meta, beta_meta)['pixel_size_um']['average']\n",
        "    z_step_um = extract_spatial_info(alpha_meta, beta_meta)['z_step_um']['average']\n",
        "    \n",
        "    print(f\"Processing parameters:\")\n",
        "    print(f\"  Pixel size: {pixel_size_um:.4f} μm\")\n",
        "    print(f\"  Z-step: {z_step_um:.4f} μm\")\n",
        "    print(f\"  Light sheet angle: 45° (standard for diSPIM)\")\n",
        "    \n",
        "    # For testing, you may want to load a subset of slices\n",
        "    # Set to None to load full stack\n",
        "    MAX_SLICES_FOR_PROCESSING = None  # Change to smaller number (e.g., 50) for faster testing\n",
        "    \n",
        "    print(f\"\\nLoading image data...\")\n",
        "    print(f\"  Max slices: {MAX_SLICES_FOR_PROCESSING if MAX_SLICES_FOR_PROCESSING else 'All'}\")\n",
        "    \n",
        "    # Load all cameras from both arms\n",
        "    alpha_data = load_ome_tiff(\n",
        "        selected_acq['alpha_tiff'],\n",
        "        metadata=alpha_meta,\n",
        "        channel_idx=None,  # Load all cameras\n",
        "        max_slices=MAX_SLICES_FOR_PROCESSING\n",
        "    )\n",
        "    \n",
        "    beta_data = load_ome_tiff(\n",
        "        selected_acq['beta_tiff'],\n",
        "        metadata=beta_meta,\n",
        "        channel_idx=None,  # Load all cameras\n",
        "        max_slices=MAX_SLICES_FOR_PROCESSING\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nData loaded:\")\n",
        "    print(f\"  Alpha shape: {alpha_data.shape}\")\n",
        "    print(f\"  Beta shape: {beta_data.shape}\")\n",
        "    print(f\"  Alpha cameras: {alpha_meta['channel_names']}\")\n",
        "    print(f\"  Beta cameras: {beta_meta['channel_names']}\")\n",
        "else:\n",
        "    print(\"No acquisition selected\")\n",
        "    alpha_data = None\n",
        "    beta_data = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 1: Deskewing\n",
        "\n",
        "Remove the 45° shear from the raw light sheet data. Each camera stack is deskewed independently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if alpha_data is not None and beta_data is not None:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"PHASE 1: DESKEWING\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Extract individual camera stacks\n",
        "    # Alpha arm: cameras 0 and 1\n",
        "    alpha_cam0_raw = alpha_data[:, 0, :, :]  # Shape: (Z, Y, X)\n",
        "    alpha_cam1_raw = alpha_data[:, 1, :, :]\n",
        "    \n",
        "    # Beta arm: cameras 0 and 1\n",
        "    beta_cam0_raw = beta_data[:, 0, :, :]\n",
        "    beta_cam1_raw = beta_data[:, 1, :, :]\n",
        "    \n",
        "    print(f\"\\nDeskewing Alpha Camera 0 ({alpha_meta['channel_names'][0]})...\")\n",
        "    alpha_cam0_deskewed, info0 = deskew_stack(\n",
        "        alpha_cam0_raw, pixel_size_um, z_step_um, angle_deg=45.0\n",
        "    )\n",
        "    print(f\"  Input shape: {info0['input_shape']}\")\n",
        "    print(f\"  Output shape: {info0['output_shape']}\")\n",
        "    \n",
        "    print(f\"\\nDeskewing Alpha Camera 1 ({alpha_meta['channel_names'][1]})...\")\n",
        "    alpha_cam1_deskewed, info1 = deskew_stack(\n",
        "        alpha_cam1_raw, pixel_size_um, z_step_um, angle_deg=45.0\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nDeskewing Beta Camera 0 ({beta_meta['channel_names'][0]})...\")\n",
        "    beta_cam0_deskewed, info2 = deskew_stack(\n",
        "        beta_cam0_raw, pixel_size_um, z_step_um, angle_deg=45.0\n",
        "    )\n",
        "    print(f\"  Input shape: {info2['input_shape']}\")\n",
        "    print(f\"  Output shape: {info2['output_shape']}\")\n",
        "    \n",
        "    print(f\"\\nDeskewing Beta Camera 1 ({beta_meta['channel_names'][1]})...\")\n",
        "    beta_cam1_deskewed, info3 = deskew_stack(\n",
        "        beta_cam1_raw, pixel_size_um, z_step_um, angle_deg=45.0\n",
        "    )\n",
        "    \n",
        "    print(\"\\nDeskewing complete!\")\n",
        "else:\n",
        "    print(\"No data loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Deskewing Results\n",
        "\n",
        "Compare raw vs deskewed Maximum Intensity Projections (MIPs) to verify the transformation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if alpha_data is not None:\n",
        "    # Compute MIPs for visualization\n",
        "    # XZ view: project along Y axis\n",
        "    alpha_cam0_raw_xz = compute_mip(alpha_cam0_raw, axis=1)\n",
        "    alpha_cam0_deskewed_xz = compute_mip(alpha_cam0_deskewed, axis=1)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Raw XZ MIP\n",
        "    raw_scaled, _, _ = scale_image_for_display(alpha_cam0_raw_xz)\n",
        "    axes[0].imshow(raw_scaled, cmap='gray', aspect='auto')\n",
        "    axes[0].set_title('Raw Data - XZ MIP (Sheared)', fontsize=14)\n",
        "    axes[0].set_xlabel('X (pixels)')\n",
        "    axes[0].set_ylabel('Z (slices)')\n",
        "    \n",
        "    # Deskewed XZ MIP\n",
        "    deskewed_scaled, _, _ = scale_image_for_display(alpha_cam0_deskewed_xz)\n",
        "    axes[1].imshow(deskewed_scaled, cmap='gray', aspect='auto')\n",
        "    axes[1].set_title('Deskewed Data - XZ MIP (Rectilinear)', fontsize=14)\n",
        "    axes[1].set_xlabel('X (pixels)')\n",
        "    axes[1].set_ylabel('Z (slices)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nNote: In the deskewed version, spherical objects should appear circular,\")\n",
        "    print(\"not elongated/oval as in the raw sheared data.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 2: Intra-Arm Camera Alignment\n",
        "\n",
        "Align the two cameras within each arm. This registers cameras that view the same sample from different angles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if alpha_data is not None:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"PHASE 2: INTRA-ARM CAMERA ALIGNMENT\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Alpha arm: align camera 1 to camera 0\n",
        "    print(f\"\\nAligning Alpha cameras: {alpha_meta['channel_names'][1]} -> {alpha_meta['channel_names'][0]}\")\n",
        "    print(\"This may take several minutes...\")\n",
        "    \n",
        "    alpha_cam1_aligned, alpha_transform, alpha_metrics = align_cameras_within_arm(\n",
        "        alpha_cam0_deskewed,  # Fixed (reference)\n",
        "        alpha_cam1_deskewed,  # Moving (to be aligned)\n",
        "        transform_type='rigid',\n",
        "        verbose=True\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nAlpha alignment metrics:\")\n",
        "    print(f\"  Final metric value: {alpha_metrics['final_metric_value']:.6f}\")\n",
        "    print(f\"  Iterations: {alpha_metrics['optimizer_iterations']}\")\n",
        "    \n",
        "    # Beta arm: align camera 1 to camera 0\n",
        "    print(f\"\\nAligning Beta cameras: {beta_meta['channel_names'][1]} -> {beta_meta['channel_names'][0]}\")\n",
        "    print(\"This may take several minutes...\")\n",
        "    \n",
        "    beta_cam1_aligned, beta_transform, beta_metrics = align_cameras_within_arm(\n",
        "        beta_cam0_deskewed,  # Fixed (reference)\n",
        "        beta_cam1_deskewed,  # Moving (to be aligned)\n",
        "        transform_type='rigid',\n",
        "        verbose=True\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nBeta alignment metrics:\")\n",
        "    print(f\"  Final metric value: {beta_metrics['final_metric_value']:.6f}\")\n",
        "    print(f\"  Iterations: {beta_metrics['optimizer_iterations']}\")\n",
        "    \n",
        "    print(\"\\nIntra-arm alignment complete!\")\n",
        "else:\n",
        "    print(\"No data loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Camera Alignment\n",
        "\n",
        "Show before/after camera overlays to verify improved alignment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if alpha_data is not None:\n",
        "    # Select a slice in the middle of the volume\n",
        "    slice_idx = alpha_cam0_deskewed.shape[0] // 2\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
        "    \n",
        "    # Alpha: Before alignment\n",
        "    alpha_before = create_camera_overlay(\n",
        "        alpha_cam0_deskewed[slice_idx, :, :],\n",
        "        alpha_cam1_deskewed[slice_idx, :, :],\n",
        "        alpha_meta['channel_names'][0],\n",
        "        alpha_meta['channel_names'][1]\n",
        "    )\n",
        "    axes[0, 0].imshow(alpha_before, aspect='equal')\n",
        "    axes[0, 0].set_title(f'Alpha: Before Alignment (Slice {slice_idx})', fontsize=12)\n",
        "    axes[0, 0].axis('off')\n",
        "    \n",
        "    # Alpha: After alignment\n",
        "    alpha_after = create_camera_overlay(\n",
        "        alpha_cam0_deskewed[slice_idx, :, :],\n",
        "        alpha_cam1_aligned[slice_idx, :, :],\n",
        "        alpha_meta['channel_names'][0],\n",
        "        alpha_meta['channel_names'][1]\n",
        "    )\n",
        "    axes[0, 1].imshow(alpha_after, aspect='equal')\n",
        "    axes[0, 1].set_title(f'Alpha: After Alignment (Slice {slice_idx})', fontsize=12)\n",
        "    axes[0, 1].axis('off')\n",
        "    \n",
        "    # Beta: Before alignment\n",
        "    beta_before = create_camera_overlay(\n",
        "        beta_cam0_deskewed[slice_idx, :, :],\n",
        "        beta_cam1_deskewed[slice_idx, :, :],\n",
        "        beta_meta['channel_names'][0],\n",
        "        beta_meta['channel_names'][1]\n",
        "    )\n",
        "    axes[1, 0].imshow(beta_before, aspect='equal')\n",
        "    axes[1, 0].set_title(f'Beta: Before Alignment (Slice {slice_idx})', fontsize=12)\n",
        "    axes[1, 0].axis('off')\n",
        "    \n",
        "    # Beta: After alignment\n",
        "    beta_after = create_camera_overlay(\n",
        "        beta_cam0_deskewed[slice_idx, :, :],\n",
        "        beta_cam1_aligned[slice_idx, :, :],\n",
        "        beta_meta['channel_names'][0],\n",
        "        beta_meta['channel_names'][1]\n",
        "    )\n",
        "    axes[1, 1].imshow(beta_after, aspect='equal')\n",
        "    axes[1, 1].set_title(f'Beta: After Alignment (Slice {slice_idx})', fontsize=12)\n",
        "    axes[1, 1].axis('off')\n",
        "    \n",
        "    plt.suptitle('Camera Alignment: Red = Camera 0, Green = Camera 1, Yellow = Overlap',\n",
        "                 fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 3: Rough Inter-Arm Alignment\n",
        "\n",
        "Transform Beta arm volumes to roughly match Alpha arm coordinate system:\n",
        "1. Flip Z-axis (Beta views from below)\n",
        "2. Rotate 90° in XY plane (Beta arm rotated 90° around Z-axis)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if alpha_data is not None:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"PHASE 3: ROUGH INTER-ARM ALIGNMENT\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Apply rough alignment to Beta cameras\n",
        "    print(\"\\nApplying rough alignment to Beta Camera 0...\")\n",
        "    beta_cam0_rough, rough_info0 = rough_align_beta_to_alpha(beta_cam0_deskewed)\n",
        "    \n",
        "    print(\"\\nApplying rough alignment to Beta Camera 1...\")\n",
        "    beta_cam1_rough, rough_info1 = rough_align_beta_to_alpha(beta_cam1_aligned)\n",
        "    \n",
        "    print(\"\\nRough alignment complete!\")\n",
        "    print(f\"  Beta Camera 0 shape: {beta_cam0_rough.shape}\")\n",
        "    print(f\"  Beta Camera 1 shape: {beta_cam1_rough.shape}\")\n",
        "else:\n",
        "    print(\"No data loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Rough Alignment\n",
        "\n",
        "Compare Alpha and Beta volumes after rough alignment to verify they're in the same orientation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if alpha_data is not None:\n",
        "    # Create fused volumes for visualization\n",
        "    alpha_fused_rough = (alpha_cam0_deskewed + alpha_cam1_aligned) / 2.0\n",
        "    beta_fused_rough = (beta_cam0_rough + beta_cam1_rough) / 2.0\n",
        "    \n",
        "    # Compute MIPs\n",
        "    alpha_mip_xy = compute_mip(alpha_fused_rough, axis=0)  # XY view\n",
        "    beta_mip_xy = compute_mip(beta_fused_rough, axis=0)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "    \n",
        "    alpha_scaled, _, _ = scale_image_for_display(alpha_mip_xy)\n",
        "    axes[0].imshow(alpha_scaled, cmap='gray', aspect='equal')\n",
        "    axes[0].set_title('Alpha Arm - XY MIP (After Deskewing & Intra-Arm Alignment)', fontsize=12)\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    beta_scaled, _, _ = scale_image_for_display(beta_mip_xy)\n",
        "    axes[1].imshow(beta_scaled, cmap='gray', aspect='equal')\n",
        "    axes[1].set_title('Beta Arm - XY MIP (After Rough Alignment)', fontsize=12)\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    plt.suptitle('Rough Alignment: Both arms should now be in same orientation', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 4: Fine Registration (Inter-Arm)\n",
        "\n",
        "Perform precise registration of Beta arm to Alpha arm using overlapping regions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if alpha_data is not None:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"PHASE 4: FINE INTER-ARM REGISTRATION\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Create fused volumes for registration\n",
        "    alpha_fused = (alpha_cam0_deskewed + alpha_cam1_aligned) / 2.0\n",
        "    beta_fused = (beta_cam0_rough + beta_cam1_rough) / 2.0\n",
        "    \n",
        "    print(f\"\\nAlpha fused shape: {alpha_fused.shape}\")\n",
        "    print(f\"Beta fused shape: {beta_fused.shape}\")\n",
        "    print(\"\\nRegistering Beta to Alpha...\")\n",
        "    print(\"This may take several minutes...\")\n",
        "    \n",
        "    beta_fused_registered, inter_arm_transform, inter_metrics = register_arms(\n",
        "        alpha_fused,  # Fixed (reference)\n",
        "        beta_fused,  # Moving (to be aligned)\n",
        "        transform_type='rigid',\n",
        "        verbose=True\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nInter-arm registration metrics:\")\n",
        "    print(f\"  Final metric value: {inter_metrics['final_metric_value']:.6f}\")\n",
        "    print(f\"  Iterations: {inter_metrics['optimizer_iterations']}\")\n",
        "    \n",
        "    # Apply the same transformation to both Beta cameras\n",
        "    print(\"\\nApplying transformation to Beta Camera 0...\")\n",
        "    beta_cam0_registered = apply_transform(\n",
        "        beta_cam0_rough,\n",
        "        inter_arm_transform,\n",
        "        reference_shape=alpha_fused.shape\n",
        "    )\n",
        "    \n",
        "    print(\"Applying transformation to Beta Camera 1...\")\n",
        "    beta_cam1_registered = apply_transform(\n",
        "        beta_cam1_rough,\n",
        "        inter_arm_transform,\n",
        "        reference_shape=alpha_fused.shape\n",
        "    )\n",
        "    \n",
        "    print(\"\\nFine registration complete!\")\n",
        "else:\n",
        "    print(\"No data loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Final Registration\n",
        "\n",
        "Show Alpha and Beta volumes overlaid to verify precise alignment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if alpha_data is not None:\n",
        "    # Create overlay of Alpha (red) and Beta (green)\n",
        "    slice_idx = alpha_fused.shape[0] // 2\n",
        "    \n",
        "    # Scale images for display\n",
        "    alpha_slice_scaled, _, _ = scale_image_for_display(alpha_fused[slice_idx, :, :])\n",
        "    beta_slice_scaled, _, _ = scale_image_for_display(beta_fused_registered[slice_idx, :, :])\n",
        "    \n",
        "    # Create RGB overlay\n",
        "    overlay = np.zeros((alpha_slice_scaled.shape[0], alpha_slice_scaled.shape[1], 3))\n",
        "    overlay[:, :, 0] = alpha_slice_scaled  # Red = Alpha\n",
        "    overlay[:, :, 1] = beta_slice_scaled   # Green = Beta\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
        "    \n",
        "    axes[0].imshow(alpha_slice_scaled, cmap='gray', aspect='equal')\n",
        "    axes[0].set_title('Alpha Arm', fontsize=12)\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    axes[1].imshow(beta_slice_scaled, cmap='gray', aspect='equal')\n",
        "    axes[1].set_title('Beta Arm (Registered)', fontsize=12)\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    axes[2].imshow(overlay, aspect='equal')\n",
        "    axes[2].set_title('Overlay: Alpha (red) + Beta (green) = Yellow', fontsize=12)\n",
        "    axes[2].axis('off')\n",
        "    \n",
        "    plt.suptitle(f'Final Registration - Slice {slice_idx}', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nIn the overlay, yellow regions indicate good alignment.\")\n",
        "    print(\"Red/green separation indicates remaining misalignment.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 5: Fusion\n",
        "\n",
        "Combine all 4 registered volumes into a single isotropic volume.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if alpha_data is not None:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"PHASE 5: VOLUME FUSION\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Fuse all 4 registered volumes\n",
        "    print(\"\\nFusing volumes:\")\n",
        "    print(f\"  - Alpha Camera 0: {alpha_meta['channel_names'][0]}\")\n",
        "    print(f\"  - Alpha Camera 1: {alpha_meta['channel_names'][1]}\")\n",
        "    print(f\"  - Beta Camera 0: {beta_meta['channel_names'][0]}\")\n",
        "    print(f\"  - Beta Camera 1: {beta_meta['channel_names'][1]}\")\n",
        "    \n",
        "    fused_volume = fuse_volumes(\n",
        "        alpha_cam0_deskewed,\n",
        "        alpha_cam1_aligned,\n",
        "        beta_cam0_registered,\n",
        "        beta_cam1_registered,\n",
        "        method='weighted_average',\n",
        "        weights=None  # Equal weights for all cameras\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nFused volume shape: {fused_volume.shape}\")\n",
        "    print(f\"Fused volume dtype: {fused_volume.dtype}\")\n",
        "    print(f\"Fused volume range: [{fused_volume.min()}, {fused_volume.max()}]\")\n",
        "    \n",
        "    print(\"\\nFusion complete!\")\n",
        "else:\n",
        "    print(\"No data loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Fused Volume\n",
        "\n",
        "Display Maximum Intensity Projections from different views of the fused volume.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if alpha_data is not None:\n",
        "    # Compute MIPs from all three views\n",
        "    mips = compute_mip_xyz(fused_volume)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
        "    \n",
        "    # XY view (project along Z)\n",
        "    xy_scaled, _, _ = scale_image_for_display(mips['xy'])\n",
        "    axes[0].imshow(xy_scaled, cmap='gray', aspect='equal')\n",
        "    axes[0].set_title('XY View (Z projection)', fontsize=12)\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # XZ view (project along Y)\n",
        "    xz_scaled, _, _ = scale_image_for_display(mips['xz'])\n",
        "    axes[1].imshow(xz_scaled, cmap='gray', aspect='auto')\n",
        "    axes[1].set_title('XZ View (Y projection)', fontsize=12)\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    # YZ view (project along X)\n",
        "    yz_scaled, _, _ = scale_image_for_display(mips['yz'])\n",
        "    axes[2].imshow(yz_scaled, cmap='gray', aspect='auto')\n",
        "    axes[2].set_title('YZ View (X projection)', fontsize=12)\n",
        "    axes[2].axis('off')\n",
        "    \n",
        "    plt.suptitle('Fused Volume - Maximum Intensity Projections', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Save Results\n",
        "\n",
        "Save the processed volumes for further analysis or visualization in other tools (e.g., Napari, Fiji).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to save results\n",
        "# if alpha_data is not None:\n",
        "#     import tifffile\n",
        "#     output_dir = Path('processed_output')\n",
        "#     output_dir.mkdir(exist_ok=True)\n",
        "#     \n",
        "#     # Save fused volume\n",
        "#     output_path = output_dir / f\"{selected_acq['condition']}_{selected_acq['run']}_fused.ome.tif\"\n",
        "#     tifffile.imwrite(\n",
        "#         str(output_path),\n",
        "#         fused_volume,\n",
        "#         photometric='minisblack',\n",
        "#         metadata={'axes': 'ZYX'}\n",
        "#     )\n",
        "#     print(f\"Saved fused volume to: {output_path}\")\n",
        "#     \n",
        "#     # Optionally save intermediate results\n",
        "#     # tifffile.imwrite(output_dir / 'alpha_cam0_deskewed.tif', alpha_cam0_deskewed)\n",
        "#     # tifffile.imwrite(output_dir / 'beta_cam0_registered.tif', beta_cam0_registered)\n",
        "#     # etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Processing Pipeline Complete!\n",
        "\n",
        "The pipeline has transformed raw double-diSPIM data through:\n",
        "\n",
        "1. ✅ **Deskewing**: Removed 45° shear from all 4 camera stacks\n",
        "2. ✅ **Intra-Arm Alignment**: Aligned cameras within Alpha and Beta arms\n",
        "3. ✅ **Rough Inter-Arm Alignment**: Transformed Beta to match Alpha coordinate system\n",
        "4. ✅ **Fine Registration**: Precisely aligned Beta to Alpha\n",
        "5. ✅ **Fusion**: Combined all volumes into single isotropic volume\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Deconvolution**: For even better resolution, apply joint multi-view deconvolution\n",
        "- **Analysis**: Use the fused volume for segmentation, tracking, or other analysis\n",
        "- **Visualization**: Load in Napari for interactive 3D exploration\n",
        "\n",
        "### Notes\n",
        "\n",
        "- Processing large volumes can be memory-intensive. Consider processing subvolumes or using dask for chunked processing.\n",
        "- Registration quality can be improved by adjusting SimpleITK parameters (learning rate, iterations, multi-resolution levels).\n",
        "- For production use, save intermediate results at each phase for debugging and reproducibility.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dispim_analysis",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
